{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOCATION EXTRACTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Picture1.png](Picture1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Loading packages into the notebook](#Loading-required-packages)\n",
    "- [Loading and exploring data](#Loading-and-exploring-data)\n",
    "- [Data preprocessing and cleaning](#Data-cleaning-and-Preprocessing)\n",
    "- [spaCy: Loading and exploring](#spaCy:-Loading-and-exploring)\n",
    "- [Extracting location entities](#Extracting-location-entities)\n",
    "- [Cleaning and combining locations](#Cleaning-and-combining-locations)\n",
    "- [Geocoding with Nominatim](#Geocoding-with-Nominatim)\n",
    "- [Visualising data](#Visualising-data)\n",
    "- [Distance Calculations](#Distance-calculation)\n",
    "- [Result visualisation](#Result-visualisation)\n",
    "- [Assignment](#Assignment)\n",
    "- [Improving results using keywords](#Grammatical-Filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data \n",
    "df = pd.read_csv('../tweets/california_tweets.csv')\n",
    "\n",
    "# shape of the data (rows, columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>src_lang</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8</td>\n",
       "      <td>Pacifica; CA</td>\n",
       "      <td>en</td>\n",
       "      <td>-122.500464</td>\n",
       "      <td>37.593650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>_styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>-121.989751</td>\n",
       "      <td>38.355840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz</td>\n",
       "      <td>East Oakdale, CA</td>\n",
       "      <td>en</td>\n",
       "      <td>-120.829960</td>\n",
       "      <td>37.774330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Warriors single game tickets go on sale at 10 a.m. https://t.co/1Ojk8wtdcg</td>\n",
       "      <td>San Jose; CA</td>\n",
       "      <td>en</td>\n",
       "      <td>-121.891766</td>\n",
       "      <td>37.332484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm at Hardly Strictly Bluegrass in San Francisco, CA https://t.co/u61jaz0kHZ</td>\n",
       "      <td>San Francisco; CA</td>\n",
       "      <td>en</td>\n",
       "      <td>-122.489542</td>\n",
       "      <td>37.771727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "4           4   \n",
       "\n",
       "                                                                                                                       text  \\\n",
       "0                                                                I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8   \n",
       "1   _styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0   \n",
       "2  Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz   \n",
       "3                                                Warriors single game tickets go on sale at 10 a.m. https://t.co/1Ojk8wtdcg   \n",
       "4                                             I'm at Hardly Strictly Bluegrass in San Francisco, CA https://t.co/u61jaz0kHZ   \n",
       "\n",
       "                place src_lang        long        lat  \n",
       "0        Pacifica; CA       en -122.500464  37.593650  \n",
       "1                 NaN       en -121.989751  38.355840  \n",
       "2    East Oakdale, CA       en -120.829960  37.774330  \n",
       "3        San Jose; CA       en -121.891766  37.332484  \n",
       "4   San Francisco; CA       en -122.489542  37.771727  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualising the first (number) rows within the dataset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Our data is made up of 2000 rows and 5 columns. The text column contains tweet posts sent from different users. The data has been filtered to return only tweets with longitude and latitude values, which will be used later on to verify the accuracy of the location extraction.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning and Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the noise in the tweet texts, we clean up our tweets before applying NLP. For this exercise we:\n",
    "\n",
    "- Return only English tweets \n",
    "- Remove special characters\n",
    "- Replace @ with at \n",
    "- Remove resulting empty cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only english tweets \n",
    "df['text_en'] = df.text\n",
    "is_english = df.src_lang == 'en'\n",
    "df.loc[is_english, 'text_en'] = df.loc[is_english, 'text']\n",
    "df = df.loc[is_english]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters\n",
    "def preprocess_tweets(tweets, remove_tokens = ('\\n', '\\r', '\\t', 'RT', r'[^\\x00-\\x7f]'),\n",
    "                meta_information_indicators = ('https:', 'http:', 'www.', '//t.co'),\n",
    "                allowed_punctuation = (',', '.', '.', '!', '?', ' ', ':', '-', ';','@')):\n",
    "    def keep_token(token):\n",
    "        return token not in remove_tokens and\\\n",
    "        not any(token.startswith(meta_token) for meta_token in meta_information_indicators)\n",
    "    \n",
    "    clean_tweets = tweets.apply(lambda x: ' '.join(filter(keep_token, x.split(' '))))\n",
    "    \n",
    "    keep_char = lambda t: t.isalnum() or t in allowed_punctuation\n",
    "    return clean_tweets.apply(lambda x: ''.join(filter(keep_char, list(x))))\n",
    "    \n",
    "clean_tweets = preprocess_tweets(df.text_en)\n",
    "df['clean_text'] = clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.nan for all missing values\n",
    "df = df.replace('-', np.nan).fillna(np.nan)\n",
    "\n",
    "# remove empty columns\n",
    "df = df.dropna(how='all', axis='columns')\n",
    "\n",
    "# remove rows without text\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "#Replace @ with at for spaCy syntax \n",
    "df.clean_text = df.clean_text.str.replace(\"@\", \"at \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>src_lang</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>text_en</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8</td>\n",
       "      <td>Pacifica; CA</td>\n",
       "      <td>en</td>\n",
       "      <td>-122.500464</td>\n",
       "      <td>37.59365</td>\n",
       "      <td>I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8</td>\n",
       "      <td>Im at My Home Gym in Pacifica, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>_styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>-121.989751</td>\n",
       "      <td>38.35584</td>\n",
       "      <td>_styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0</td>\n",
       "      <td>styledbym.e killed it with this shadowroot colormelt on ahlthaaat! Color melting, Balayage,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz</td>\n",
       "      <td>East Oakdale, CA</td>\n",
       "      <td>en</td>\n",
       "      <td>-120.829960</td>\n",
       "      <td>37.77433</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "\n",
       "                                                                                                                       text  \\\n",
       "0                                                                I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8   \n",
       "1   _styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0   \n",
       "2  Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz   \n",
       "\n",
       "              place src_lang        long       lat  \\\n",
       "0      Pacifica; CA       en -122.500464  37.59365   \n",
       "1               NaN       en -121.989751  38.35584   \n",
       "2  East Oakdale, CA       en -120.829960  37.77433   \n",
       "\n",
       "                                                                                                                    text_en  \\\n",
       "0                                                                I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8   \n",
       "1   _styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0   \n",
       "2  Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz   \n",
       "\n",
       "                                                                                      clean_text  \n",
       "0                                                              Im at My Home Gym in Pacifica, CA  \n",
       "1    styledbym.e killed it with this shadowroot colormelt on ahlthaaat! Color melting, Balayage,  \n",
       "2  Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8</td>\n",
       "      <td>Pacifica; CA</td>\n",
       "      <td>-122.500464</td>\n",
       "      <td>37.59365</td>\n",
       "      <td>Im at My Home Gym in Pacifica, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-121.989751</td>\n",
       "      <td>38.35584</td>\n",
       "      <td>styledbym.e killed it with this shadowroot colormelt on ahlthaaat! Color melting, Balayage,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz</td>\n",
       "      <td>East Oakdale, CA</td>\n",
       "      <td>-120.829960</td>\n",
       "      <td>37.77433</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       text  \\\n",
       "0                                                                I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8   \n",
       "1   _styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0   \n",
       "2  Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz   \n",
       "\n",
       "              place        long       lat  \\\n",
       "0      Pacifica; CA -122.500464  37.59365   \n",
       "1               NaN -121.989751  38.35584   \n",
       "2  East Oakdale, CA -120.829960  37.77433   \n",
       "\n",
       "                                                                                      clean_text  \n",
       "0                                                              Im at My Home Gym in Pacifica, CA  \n",
       "1    styledbym.e killed it with this shadowroot colormelt on ahlthaaat! Color melting, Balayage,  \n",
       "2  Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping some columns to reduce data size to necessary columns \n",
    "\n",
    "# Make sure to only run this cell once as a duplicate returns error of cells not found\n",
    "df = df.drop(['Unnamed: 0', 'src_lang', 'text_en'], axis = 1 )\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .loc to define a slice of rows you would like to view from you data\n",
    "\n",
    "#df1.loc[100:162]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "> What other preprocessing routines could be done or what preprocessing steps could be left out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy: Loading and exploring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**spaCy**](https://spacy.io/) is a NLP tool developed by Explosion to extract entities in text. Unlike most NLP packages that rely on a Gazetteer to extract locations, spaCy uses word embedding to determine the entity class of a word within the sentence syntax. The advantage of this approach is that it is able to return locations even with spelling errors. Disadvantage is possible false positives due to different sentence syntaxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading spaCy packages \n",
    "import spacy\n",
    "from spacy import displacy # Displacy is used to visualise spaCy tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the spaCy model \n",
    "nlp =spacy.load('en_core_web_trf') # model trf higher accuracy, bigger model, slower in exercution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "Before extracting locations within the dataset, we can first play around with self-made example sentences to explore how spaCy works. You can rewrite your own sentences and explore what kind of results spaCy would return.\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sentences \n",
    "\n",
    "doc = nlp(\"\"\"Hello everyone, welcome to the 2021 summer semester Spring School.\n",
    "        The University of Salzburg in Salzburg, Austria presents the spring school\n",
    "         Did you know, Michael Jackson's jacket was valued at 10 billion dollars?\n",
    "        I first have to Google why Google has so many employees.\n",
    "        Zara and I are doing some shopping in Ikea after which we visit the Hellbrun Palace.\n",
    "        I love the taste of New York Pizza especially when I am in New York\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hello everyone, welcome to the \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2021\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " summer semester Spring School.</br>        \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    The University of Salzburg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Salzburg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Austria\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " presents the spring school</br>         Did you know, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Michael Jackson's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " jacket was valued at \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    10 billion dollars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "?</br>        I first have to Google why \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Google\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has so many employees.</br>        \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zara\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and I are doing some shopping in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ikea\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " after which we visit \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the Hellbrun Palace\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">FAC</span>\n",
       "</mark>\n",
       ".</br>        I love the taste of New York Pizza especially when I am in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising spaCy entities\n",
    "displacy.render(doc, style = \"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buildings, airports, highways, bridges, etc.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spacy.explain is used to define the entities returned by spaCy\n",
    "spacy.explain(\"FAC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ORG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample instance creation\n",
    "\n",
    "doc1 = nlp(\"Helen is a great tutor and communicator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Helen\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is a great tutor and communicator</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#spacy entities\n",
    "displacy.render(doc1, style = \"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    ">Experiment with spaCy writing different sentence structures. Are they any instances where spaCy wrongly detects or omits an entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting location entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get location information \n",
    "def filter_location_entities(entities):\n",
    "    locations = []\n",
    "    for entity in entities:\n",
    "        if entity.label_ == 'GPE':\n",
    "                locations.append(entity)\n",
    "                \n",
    "    return locations\n",
    "\n",
    "def filter_location_entities1(entities):\n",
    "    locations1 = []\n",
    "    for entity in entities:\n",
    "        if entity.label_ == 'FAC':\n",
    "                locations1.append(entity)\n",
    "                      \n",
    "    return locations1\n",
    "\n",
    "def filter_location_entities2(entities):\n",
    "    locations2 = []\n",
    "    for entity in entities:\n",
    "        if entity.label_ == 'ORG':\n",
    "                locations2.append(entity)\n",
    "                      \n",
    "    return locations2\n",
    "\n",
    "def filter_location_entities3(entities):\n",
    "    locations3 = []\n",
    "    for entity in entities:\n",
    "        if entity.label_ == 'LOC':\n",
    "                locations3.append(entity)\n",
    "                      \n",
    "    return locations3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f68ad8df15ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#creates a new column, ner_text, with entities extracted from the 'text' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GPE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter_location_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FAC'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter_location_entities1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ORG'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter_location_entities2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOC'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter_location_entities3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f68ad8df15ed>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#creates a new column, ner_text, with entities extracted from the 'text' column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GPE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter_location_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FAC'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter_location_entities1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ORG'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter_location_entities2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOC'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilter_location_entities3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/spacy_transformers/pipeline_component.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mnightly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;31m#call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \"\"\"\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/spacy_transformers/pipeline_component.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFullTransformerBatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mbatch_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerListener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlistener\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisteners\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/thinc/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/spacy_transformers/layers/transformer_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, docs, is_train)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mwordpieces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_max_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     )\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordpieces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"logger\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mlog_gpu_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"logger\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"after forward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    287\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/thinc/layers/pytorchwrapper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mXtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mYtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_backprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dYtorch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtorch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/thinc/shims/pytorch.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, is_train)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArgsKwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/thinc/shims/pytorch.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    809\u001b[0m         )\n\u001b[1;32m    810\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;31m# to the first token.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mfirst_token_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_token_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#creates a new column, ner_text, with entities extracted from the 'text' column\n",
    "df['GPE'] = df['clean_text'].astype(str).apply(lambda x: filter_location_entities(nlp(x).ents))\n",
    "df['FAC'] = df['clean_text'].astype(str).apply(lambda x: filter_location_entities1(nlp(x).ents))\n",
    "df['ORG'] = df['clean_text'].astype(str).apply(lambda x: filter_location_entities2(nlp(x).ents))\n",
    "df['LOC'] = df['clean_text'].astype(str).apply(lambda x: filter_location_entities3(nlp(x).ents))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "Time taken in extracting location entities from a data frame increases with the number of rows present in the data frame. It is often advisable to save the file locally within your PC in case the notebook fails, you will not have to rerun the extraction process again.\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../tweets/df_location_entities1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e650d021663b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Saving dataframe with extracted location entities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moutfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'../tweets/df_location_entities1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         )\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             )\n\u001b[1;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '../tweets/df_location_entities1.csv'"
     ]
    }
   ],
   "source": [
    "#Saving dataframe with extracted location entities \n",
    "outfilename = ('../tweets/df_location_entities1.csv')\n",
    "df.to_csv(outfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and combining locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>GPE</th>\n",
       "      <th>FAC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8</td>\n",
       "      <td>Pacifica; CA</td>\n",
       "      <td>-122.500464</td>\n",
       "      <td>37.59365</td>\n",
       "      <td>Im at My Home Gym in Pacifica, CA</td>\n",
       "      <td>[Pacifica, CA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>_styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-121.989751</td>\n",
       "      <td>38.35584</td>\n",
       "      <td>styledbym.e killed it with this shadowroot colormelt on ahlthaaat! Color melting, Balayage,</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz</td>\n",
       "      <td>East Oakdale, CA</td>\n",
       "      <td>-120.829960</td>\n",
       "      <td>37.77433</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Primigi]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "\n",
       "                                                                                                                       text  \\\n",
       "0                                                                I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8   \n",
       "1   _styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0   \n",
       "2  Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz   \n",
       "\n",
       "              place        long       lat  \\\n",
       "0      Pacifica; CA -122.500464  37.59365   \n",
       "1               NaN -121.989751  38.35584   \n",
       "2  East Oakdale, CA -120.829960  37.77433   \n",
       "\n",
       "                                                                                      clean_text  \\\n",
       "0                                                              Im at My Home Gym in Pacifica, CA   \n",
       "1    styledbym.e killed it with this shadowroot colormelt on ahlthaaat! Color melting, Balayage,   \n",
       "2  Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to   \n",
       "\n",
       "              GPE FAC        ORG LOC  \n",
       "0  [Pacifica, CA]  []         []  []  \n",
       "1              []  []         []  []  \n",
       "2              []  []  [Primigi]  []  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data with location entities extracted\n",
    "df = pd.read_csv('../tweets/df_location_entities1.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1902, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>GPE</th>\n",
       "      <th>FAC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8</td>\n",
       "      <td>Pacifica; CA</td>\n",
       "      <td>-122.500464</td>\n",
       "      <td>37.593650</td>\n",
       "      <td>Im at My Home Gym in Pacifica, CA</td>\n",
       "      <td>Pacifica, CA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>_styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-121.989751</td>\n",
       "      <td>38.355840</td>\n",
       "      <td>styledbym.e killed it with this shadowroot colormelt on ahlthaaat! Color melting, Balayage,</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz</td>\n",
       "      <td>East Oakdale, CA</td>\n",
       "      <td>-120.829960</td>\n",
       "      <td>37.774330</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Primigi</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Warriors single game tickets go on sale at 10 a.m. https://t.co/1Ojk8wtdcg</td>\n",
       "      <td>San Jose; CA</td>\n",
       "      <td>-121.891766</td>\n",
       "      <td>37.332484</td>\n",
       "      <td>Warriors single game tickets go on sale at 10 a.m.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "2           2   \n",
       "3           3   \n",
       "\n",
       "                                                                                                                       text  \\\n",
       "0                                                                I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8   \n",
       "1   _styledbym.e killed it with this #shadowroot #colormelt on ahlthaaat! Color melting, Balayage,… https://t.co/NUhTgcCim0   \n",
       "2  Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz   \n",
       "3                                                Warriors single game tickets go on sale at 10 a.m. https://t.co/1Ojk8wtdcg   \n",
       "\n",
       "              place        long        lat  \\\n",
       "0      Pacifica; CA -122.500464  37.593650   \n",
       "1               NaN -121.989751  38.355840   \n",
       "2  East Oakdale, CA -120.829960  37.774330   \n",
       "3      San Jose; CA -121.891766  37.332484   \n",
       "\n",
       "                                                                                      clean_text  \\\n",
       "0                                                              Im at My Home Gym in Pacifica, CA   \n",
       "1    styledbym.e killed it with this shadowroot colormelt on ahlthaaat! Color melting, Balayage,   \n",
       "2  Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to   \n",
       "3                                             Warriors single game tickets go on sale at 10 a.m.   \n",
       "\n",
       "            GPE FAC      ORG LOC  \n",
       "0  Pacifica, CA                   \n",
       "1                                 \n",
       "2                    Primigi      \n",
       "3                                 "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning: Remove square brakets from location entities\n",
    "df['GPE'] =  df['GPE'].apply(lambda x: x.replace('[','').replace(']',''))\n",
    "df['FAC'] =  df['FAC'].apply(lambda x: x.replace('[','').replace(']',''))\n",
    "df['ORG'] =  df['ORG'].apply(lambda x: x.replace('[','').replace(']',''))\n",
    "df['LOC'] =  df['LOC'].apply(lambda x: x.replace('[','').replace(']',''))\n",
    "\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>GPE</th>\n",
       "      <th>FAC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8</td>\n",
       "      <td>Pacifica; CA</td>\n",
       "      <td>-122.500464</td>\n",
       "      <td>37.593650</td>\n",
       "      <td>Im at My Home Gym in Pacifica, CA</td>\n",
       "      <td>Pacifica, CA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz</td>\n",
       "      <td>East Oakdale, CA</td>\n",
       "      <td>-120.829960</td>\n",
       "      <td>37.774330</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Primigi</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm at Hardly Strictly Bluegrass in San Francisco, CA https://t.co/u61jaz0kHZ</td>\n",
       "      <td>San Francisco; CA</td>\n",
       "      <td>-122.489542</td>\n",
       "      <td>37.771727</td>\n",
       "      <td>Im at Hardly Strictly Bluegrass in San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Forgotten, on a side walk. Understood. @ Western Addition, San Francisco https://t.co/pXozNjtGLF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-122.428000</td>\n",
       "      <td>37.782500</td>\n",
       "      <td>Forgotten, on a side walk. Understood. at  Western Addition, San Francisco</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Western Addition</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "2           2   \n",
       "4           4   \n",
       "9          10   \n",
       "\n",
       "                                                                                                                       text  \\\n",
       "0                                                                I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8   \n",
       "2  Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz   \n",
       "4                                             I'm at Hardly Strictly Bluegrass in San Francisco, CA https://t.co/u61jaz0kHZ   \n",
       "9                          Forgotten, on a side walk. Understood. @ Western Addition, San Francisco https://t.co/pXozNjtGLF   \n",
       "\n",
       "                place        long        lat  \\\n",
       "0        Pacifica; CA -122.500464  37.593650   \n",
       "2    East Oakdale, CA -120.829960  37.774330   \n",
       "4   San Francisco; CA -122.489542  37.771727   \n",
       "9                 NaN -122.428000  37.782500   \n",
       "\n",
       "                                                                                      clean_text  \\\n",
       "0                                                              Im at My Home Gym in Pacifica, CA   \n",
       "2  Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to   \n",
       "4                                           Im at Hardly Strictly Bluegrass in San Francisco, CA   \n",
       "9                     Forgotten, on a side walk. Understood. at  Western Addition, San Francisco   \n",
       "\n",
       "                 GPE               FAC      ORG LOC  \n",
       "0       Pacifica, CA                                 \n",
       "2                                       Primigi      \n",
       "4  San Francisco, CA                                 \n",
       "9      San Francisco  Western Addition               "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping rows without location entity extracted\n",
    "# In this case we drop rows where neither of the four location entities have location extracted.\n",
    "\n",
    "index_names = df[(df['GPE']== '') & (df['FAC']== '') & (df['ORG']== '') & (df['LOC']== '')].index\n",
    "df.drop(index_names, inplace = True)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>GPE</th>\n",
       "      <th>FAC</th>\n",
       "      <th>ORG</th>\n",
       "      <th>LOC</th>\n",
       "      <th>FAC_GPE</th>\n",
       "      <th>ORG_GPE</th>\n",
       "      <th>LOC_GPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8</td>\n",
       "      <td>Pacifica; CA</td>\n",
       "      <td>-122.500464</td>\n",
       "      <td>37.593650</td>\n",
       "      <td>Im at My Home Gym in Pacifica, CA</td>\n",
       "      <td>Pacifica, CA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz</td>\n",
       "      <td>East Oakdale, CA</td>\n",
       "      <td>-120.829960</td>\n",
       "      <td>37.774330</td>\n",
       "      <td>Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Primigi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I'm at Hardly Strictly Bluegrass in San Francisco, CA https://t.co/u61jaz0kHZ</td>\n",
       "      <td>San Francisco; CA</td>\n",
       "      <td>-122.489542</td>\n",
       "      <td>37.771727</td>\n",
       "      <td>Im at Hardly Strictly Bluegrass in San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Forgotten, on a side walk. Understood. @ Western Addition, San Francisco https://t.co/pXozNjtGLF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-122.428000</td>\n",
       "      <td>37.782500</td>\n",
       "      <td>Forgotten, on a side walk. Understood. at  Western Addition, San Francisco</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Western Addition</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Western Addition, San Francisco</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>@StarlineSC #lightshow @ Starline Social Club https://t.co/kuFUfDR76h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-122.272507</td>\n",
       "      <td>37.812812</td>\n",
       "      <td>at StarlineSC lightshow at  Starline Social Club</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Starline Social Club</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>1982</td>\n",
       "      <td>#sunrise #pier14 #sanfrancisco #ca @ Pier 14 Embarcadero San Francisco California https://t.co/Q6hklEPWLx</td>\n",
       "      <td>South Beach; San Francisco</td>\n",
       "      <td>-122.389897</td>\n",
       "      <td>37.794424</td>\n",
       "      <td>sunrise pier14 sanfrancisco ca at  Pier 14 Embarcadero San Francisco California</td>\n",
       "      <td>San Francisco, California</td>\n",
       "      <td>Pier 14 Embarcadero</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pier 14 Embarcadero, San Francisco, California</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>1991</td>\n",
       "      <td>Drinking an IPA by @lagunitasbeer @ Craig Martin Home Brews — https://t.co/yK9bH3fzRV</td>\n",
       "      <td>Pittsburg, CA</td>\n",
       "      <td>-121.884000</td>\n",
       "      <td>38.001300</td>\n",
       "      <td>Drinking an IPA by at lagunitasbeer at  Craig Martin Home Brews</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Craig Martin Home Brews</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>1992</td>\n",
       "      <td>Warriors win 😀 @ Oracle Arena and Oakland Alameda County Coliseum https://t.co/yyozENrXXy</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>-122.202223</td>\n",
       "      <td>37.750748</td>\n",
       "      <td>Warriors win  at  Oracle Arena and Oakland Alameda County Coliseum</td>\n",
       "      <td></td>\n",
       "      <td>Oracle Arena, Oakland Alameda County Coliseum</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>1994</td>\n",
       "      <td>@SanJoseSharks WIN 3-2 IN OT #SJSharks https://t.co/WjvBPJuyox</td>\n",
       "      <td>San Jose; CA</td>\n",
       "      <td>-121.900758</td>\n",
       "      <td>37.332135</td>\n",
       "      <td>at SanJoseSharks WIN 3-2 IN OT SJSharks</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SanJoseSharks, SJSharks</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>1999</td>\n",
       "      <td>Just posted a photo @ Bay Bridge, San Francisco https://t.co/jqAU39ZINP</td>\n",
       "      <td>San Francisco; CA</td>\n",
       "      <td>-122.405494</td>\n",
       "      <td>37.769230</td>\n",
       "      <td>Just posted a photo at  Bay Bridge, San Francisco</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Bay Bridge</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Bay Bridge, San Francisco</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>668 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  \\\n",
       "0              0   \n",
       "2              2   \n",
       "4              4   \n",
       "9             10   \n",
       "10            11   \n",
       "...          ...   \n",
       "1885        1982   \n",
       "1893        1991   \n",
       "1894        1992   \n",
       "1896        1994   \n",
       "1901        1999   \n",
       "\n",
       "                                                                                                                          text  \\\n",
       "0                                                                   I'm at My Home Gym in Pacifica, CA https://t.co/fWgIms86T8   \n",
       "2     Primigi Classic loafers for your boy or girl. Normally $74-$89 We have many sizes and colors to… https://t.co/ntc7OX5zyz   \n",
       "4                                                I'm at Hardly Strictly Bluegrass in San Francisco, CA https://t.co/u61jaz0kHZ   \n",
       "9                             Forgotten, on a side walk. Understood. @ Western Addition, San Francisco https://t.co/pXozNjtGLF   \n",
       "10                                                       @StarlineSC #lightshow @ Starline Social Club https://t.co/kuFUfDR76h   \n",
       "...                                                                                                                        ...   \n",
       "1885                 #sunrise #pier14 #sanfrancisco #ca @ Pier 14 Embarcadero San Francisco California https://t.co/Q6hklEPWLx   \n",
       "1893                                     Drinking an IPA by @lagunitasbeer @ Craig Martin Home Brews — https://t.co/yK9bH3fzRV   \n",
       "1894                                 Warriors win 😀 @ Oracle Arena and Oakland Alameda County Coliseum https://t.co/yyozENrXXy   \n",
       "1896                                                            @SanJoseSharks WIN 3-2 IN OT #SJSharks https://t.co/WjvBPJuyox   \n",
       "1901                                                   Just posted a photo @ Bay Bridge, San Francisco https://t.co/jqAU39ZINP   \n",
       "\n",
       "                            place        long        lat  \\\n",
       "0                    Pacifica; CA -122.500464  37.593650   \n",
       "2                East Oakdale, CA -120.829960  37.774330   \n",
       "4               San Francisco; CA -122.489542  37.771727   \n",
       "9                             NaN -122.428000  37.782500   \n",
       "10                            NaN -122.272507  37.812812   \n",
       "...                           ...         ...        ...   \n",
       "1885   South Beach; San Francisco -122.389897  37.794424   \n",
       "1893                Pittsburg, CA -121.884000  38.001300   \n",
       "1894                  Oakland, CA -122.202223  37.750748   \n",
       "1896                 San Jose; CA -121.900758  37.332135   \n",
       "1901            San Francisco; CA -122.405494  37.769230   \n",
       "\n",
       "                                                                                         clean_text  \\\n",
       "0                                                                 Im at My Home Gym in Pacifica, CA   \n",
       "2     Primigi Classic loafers for your boy or girl. Normally 74-89 We have many sizes and colors to   \n",
       "4                                              Im at Hardly Strictly Bluegrass in San Francisco, CA   \n",
       "9                        Forgotten, on a side walk. Understood. at  Western Addition, San Francisco   \n",
       "10                                                 at StarlineSC lightshow at  Starline Social Club   \n",
       "...                                                                                             ...   \n",
       "1885                sunrise pier14 sanfrancisco ca at  Pier 14 Embarcadero San Francisco California   \n",
       "1893                               Drinking an IPA by at lagunitasbeer at  Craig Martin Home Brews    \n",
       "1894                             Warriors win  at  Oracle Arena and Oakland Alameda County Coliseum   \n",
       "1896                                                        at SanJoseSharks WIN 3-2 IN OT SJSharks   \n",
       "1901                                              Just posted a photo at  Bay Bridge, San Francisco   \n",
       "\n",
       "                            GPE  \\\n",
       "0                  Pacifica, CA   \n",
       "2                                 \n",
       "4             San Francisco, CA   \n",
       "9                 San Francisco   \n",
       "10                                \n",
       "...                         ...   \n",
       "1885  San Francisco, California   \n",
       "1893                              \n",
       "1894                              \n",
       "1896                              \n",
       "1901              San Francisco   \n",
       "\n",
       "                                                FAC                      ORG  \\\n",
       "0                                                                              \n",
       "2                                                                    Primigi   \n",
       "4                                                                              \n",
       "9                                  Western Addition                            \n",
       "10                                                      Starline Social Club   \n",
       "...                                             ...                      ...   \n",
       "1885                            Pier 14 Embarcadero                            \n",
       "1893                                                 Craig Martin Home Brews   \n",
       "1894  Oracle Arena, Oakland Alameda County Coliseum                            \n",
       "1896                                                 SanJoseSharks, SJSharks   \n",
       "1901                                     Bay Bridge                            \n",
       "\n",
       "     LOC                                         FAC_GPE ORG_GPE LOC_GPE  \n",
       "0                                                                         \n",
       "2                                                                         \n",
       "4                                                                         \n",
       "9                        Western Addition, San Francisco                  \n",
       "10                                                                        \n",
       "...   ..                                             ...     ...     ...  \n",
       "1885      Pier 14 Embarcadero, San Francisco, California                  \n",
       "1893                                                                      \n",
       "1894                                                                      \n",
       "1896                                                                      \n",
       "1901                           Bay Bridge, San Francisco                  \n",
       "\n",
       "[668 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining locational entities to get finer and more informed place names\n",
    "# Locations are combined only when both columns are not null\n",
    "\n",
    "df['FAC_GPE'] = np.where(((df['FAC'] != '') & (df['GPE'] != '')), df['FAC'].str.cat(df['GPE'], sep = \", \"), '')\n",
    "df['ORG_GPE'] = np.where(((df['ORG'] != '') & (df['GPE'] != '')), df['ORG'].str.cat(df['GPE'], sep = \", \"), '')\n",
    "df['LOC_GPE'] = np.where(((df['LOC'] != '') & (df['GPE'] != '')), df['LOC'].str.cat(df['GPE'], sep = \", \"), '')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "We combine location entities in a manner that resembles actual addresses starting with a finer place name example **Building name: Stein Hotel** to a more course place reference **city name: Salzburg** to an even coarser place name e.g. **Country: Austria**\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Which other location combinations would make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocoding with Nominatim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required packages for geocoding with Nominatim\n",
    "import geopandas as gpd \n",
    "import geopy\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial \n",
    "from geopy import distance\n",
    "from geopy.distance import geodesic\n",
    "from tqdm import tqdm, tqdm_notebook # progress bar\n",
    "\n",
    "#initiate \n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_agent is used to overide restricts of using Nominatim default user_agent.\n",
    "locator = geopy.geocoders.Nominatim(user_agent='mygeocoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to avoid the error of 'Too many requests 429 error'\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=1)\n",
    "\n",
    "# return locations in english \n",
    "geocode = partial(locator.geocode, language = \"en\", timeout = 30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "[**Nominatim**](https://nominatim.org/release-docs/latest/) has a limit of 1 request per second which translates to 86 400 requests per day without retries. Depending on the number of retries done on an address, the final returned results on a single day will certainly be lower than 86 400. Furthermore, Nominatim blocks users from sending multiple requests of the same location. \n",
    "\n",
    "To reduce geocoding time and avoid being blocked, we geocode only the unique locations and map results to our dataset. \n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count unique locations in column FAC_GPE\n",
    "df['FAC_GPE'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unique_FAC_GPE = df.groupby('FAC_GPE')['Unnamed: 0'].unique()\n",
    "outfilename = ('unique_FAC_GPE.csv')\n",
    "unique_FAC_GPE.to_csv(outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('unique_FAC_GPE.csv')\n",
    "df1.loc[2:10] # Extracting a slice of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extracting locations (raw, latitude, longitude)\n",
    "\n",
    "df1['geocoded_locations'] = df1['FAC_GPE'].progress_apply(geocode)\n",
    "\n",
    "df1['Lat2'] = df1['geocoded_locations'].apply(lambda x: x.latitude if x else None)\n",
    "df1['Lon2'] = df1['geocoded_locations'].apply(lambda x: x.longitude if x else None)\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merging unique geocoded locations to full dataframe \n",
    "\n",
    "df2 = pd.merge(df1,df, on='FAC_GPE')\n",
    "df3 =df2[['clean_text','FAC_GPE', 'long', 'lat', 'Lon2', 'Lat2']]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output file \n",
    "outfilename = ('geocoded_FAC_GPE.csv')\n",
    "df3.to_csv(outfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping geocoded locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FAC_GPE = pd.read_csv('geocoded_FAC_GPE.csv') \n",
    "df_FAC_GPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataframe with geocoded values returned\n",
    "df_FAC_GPE_cleaned = df_FAC_GPE[df_FAC_GPE['Lon2'].notna()]\n",
    "df_FAC_GPE_cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FAC_GPE_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "**Exercise**\n",
    ">- More than 50% of the extracted FAC_GPE locations where not geocoded. What can be the reason for Nominatim's failure to geocode these locations?\n",
    ">- HINT: Use another geocoding service for example Google Maps to check the locations availability. Also check the locations on Open Street Map (Nominatim) service on your browser.\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map visualising packages\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBaseMap(default_location=[37.693943, -122.385880], default_zoom_start=12):\n",
    "    base_map = folium.Map(location=default_location, control_scale=True, zoom_start=default_zoom_start)\n",
    "    return base_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = statistics.mean(df_FAC_GPE_cleaned['Lat2']) \n",
    "x = statistics.mean(df_FAC_GPE_cleaned['Lon2']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "df_FAC_GPE_cleaned['count'] = 1\n",
    "base_map = generateBaseMap([y,x],8)\n",
    "HeatMap(data=df_FAC_GPE_cleaned[['Lat2', 'Lon2', 'count']].groupby(['Lat2', 'Lon2']).sum().reset_index().values.tolist(), radius=8, max_zoom=13).add_to(base_map)\n",
    "display(base_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance calculation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute displacements between the GNSS (Ground truth) and the geocoded locations. We use the displacements to measure the precision of the geocoded locations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_calc (row):\n",
    "    start = (row['lat'], row['long'])\n",
    "    stop = (row['Lat2'], row['Lon2'])\n",
    "\n",
    "    return geodesic(start, stop).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FAC_GPE_cleaned['distance'] = df_FAC_GPE_cleaned.apply (lambda row: distance_calc (row),axis=1)\n",
    "df_FAC_GPE_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising displacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining names of class\n",
    "displacements = [\"1km\", \"5km\", \"10km\", \"Over 10km\"]\n",
    "\n",
    "FAC_GPE_displacements = pd.cut(df_FAC_GPE_cleaned['distance'], [0, 1, 5, 10, 100000.0], labels=displacements) \n",
    "pd.value_counts(FAC_GPE_displacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FAC_GPE_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<spacy.scorer.Scorer object at 0x7f94bf0401d0>\n"
     ]
    }
   ],
   "source": [
    "from spacy.scorer import Scorer\n",
    "scorer = Scorer()\n",
    "\n",
    "scorer = Scorer(nlp)\n",
    "print(scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy.gold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-92e38777b89d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfbeta_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoldParse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#load NER model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy.gold'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "import spacy\n",
    "from spacy.gold import GoldParse\n",
    "\n",
    "nlp = spacy.load(\"en\") #load NER model\n",
    "test_text = \"my name is John\" # text to test accuracy\n",
    "doc_to_test = nlp(test_text) # transform the text to spacy doc format\n",
    "\n",
    "# we create a golden doc where we know the tagged entity for the text to be tested\n",
    "doc_gold_text= nlp.make_doc(test_text)\n",
    "entity_offsets_of_gold_text = [(11, 15,\"PERSON\")]\n",
    "gold = GoldParse(doc_gold_text, entities=entity_offsets_of_gold_text)\n",
    "\n",
    "# bring the data in a format acceptable for sklearn f1 function\n",
    "y_true = [\"PERSON\" if \"PERSON\" in x else 'O' for x in gold.ner]\n",
    "y_predicted = [x.ent_type_ if x.ent_type_ !='' else 'O' for x in doc_to_test]\n",
    "f1_score(y_true, y_predicted, average='macro')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "**Exercise**\n",
    "\n",
    "- Look at the tweets with distance over 10km. What are the reasons for the big distance?\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class is split into two groups. Each group will have 1 unique task, after which results are shared amoungst the groups and an overal task where both groups discuss on the process of the location extraction and geocoding exercise.  \n",
    "\n",
    "> *Use the location extraction annotation notebook for the assignment.*\n",
    ">\n",
    "> *Annotation Manual.pdf contains the labelling instructions for both exercises*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "**Group 1:**\n",
    "\n",
    "To get a better understanding of our results, we need to check how well the model performs. [**F-score, F1-score**](https://deepai.org/machine-learning-glossary-and-terms/f-score) is used to evaluate our location extaction model by computing the confusion matrix (False positive, False negative, True positive, True positive) and combining the precision and recall of the model. To compute the F-score we will label our data for the presence or absence of a location and compare the extracted output against the expected output. Essentially we want to reduce the number of false positive and false negative location extractions and increase the number of true positives and true negative location extractions.\n",
    "\n",
    ">- label data for the presence or absence of a location entity.\n",
    ">- Compute F-score of the model as [1] a geometric mean (Basic F-score) and [2] by considering either recall or precision as more important (provide arguments for your considerations). \n",
    ">- Discuss the obtained F-score values and their implications on the study results. \n",
    ">- Are there any instances which struck out when reviewing the results either when a correct location was extracted together with noise (text not part of the location) or when part of a location is extracted for example York instead of New York? What do we do with such instance?\n",
    "****\n",
    "****\n",
    "\n",
    "**Group 2:**\n",
    "\n",
    "For our case study, we want to extract locations where a user is and not a place reference from the past or future. In the prior steps, we have extracted all location mentions within our tweet dataset regardless of the temporal reference. The unfiltered place references might be one of the reasons for obtaining very high displacements between user location and mentioned location. To avoid computing locations of referenced locations we will label our data with 2 classes; user's present location and other. The aim of this assignment is to filter out referenced locations where a user is not thereby reducing the displacement between the users actual location and the predicted location.  \n",
    "\n",
    ">- Label time frame of location reference (Present time / other)\n",
    ">- Compute and compare the displacements between the two groups of labels and discuss the results.  \n",
    ">- To avoid constantly having to manually label the dataset, discuss strategies that can be used to split temporal references?  \n",
    ">- Going through the data, are there any instances where the geocoding service (Nominatim) fails to geocode a correct location or geocodes to a wrong location? What can be done on such instances?\n",
    "\n",
    "****\n",
    "****\n",
    "**Overal:**\n",
    "\n",
    " Share your findings from the individual group exercises. Discuss the presented method used in the notebook to extract and geocode locations:\n",
    ">- Preprocessing routins \n",
    ">- spaCy entity extraction\n",
    ">- entity combinations \n",
    ">- Nominatim geocoding \n",
    "\n",
    "How can this approach be improved \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possibly useful codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining search area\n",
    "# By running this line of code before geocoding we restrict the search area to locations within California\n",
    "# The code then reduces locations like CA from being geocoded to Canada instead of Califonia\n",
    "\n",
    "#geocode = lambda query: locator.geocode(\"%s, California, USA\" % query, timeout = 30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammatical Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining keywords for historial mentions \n",
    "\n",
    "\"\"\"past_keywords = [travelled to\", \"Last week\", 'last night', 'last Monday', 'last tuesday', \n",
    "                  'last wednesday', 'last thursday', 'last friday', 'last saturday', 'last month', \n",
    "                 'last year', 'last winter', 'last summer', 'last autumn', 'last days'  \"yesterday\", \n",
    "                 \"I was in \", 'were in', 'I was at', \"I went\", \"was at \", 'was in ', 'were at ', 'went to ',\n",
    "                 \"landed from\", \"passed through\", \"had visited\", 'had gone to', \"flew from\", 'flew in from',\n",
    "                 'back from', \"throwback\", \"past years\", \"miss being in\", \"I miss \", 'years ago ', 'days ago ',\n",
    "                 'months ago ', 'hours ago ', 'time ago ', 'was leaving in ', 'was staying at', 'was leaving at',\n",
    "                 'was staying in', 'makes me miss', 'im from', 'are from ', 'originally from', 'grew up in', 'grew up at ']\n",
    "\"\"\"\n",
    "#past_searched = '|'.join(past_keywords) # for searching keywords within sentence structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filtering the data to return only data with the specific keyword\n",
    "# case = False makes the search case insensitive \n",
    "# na = false means we dont return errors when there are unexpected types in series \n",
    "\n",
    "df_past = df[df[\"clean_text\"].str.contains(past_searched, case = False, na = False)]\n",
    "df_past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining keywords for future mentions \n",
    "# We add space before and after 'to' to make the text standalone\n",
    "\n",
    "\"\"\"future_keywords = [\"going to \",'driving to', \"Taking the train to\", \"taking the car to\",\n",
    "                   \"taking the bus on\", \"headin to\",'heading to', 'headed for', \"leave for\",\n",
    "                   \"leaving for\", 'go to', 'travel to', 'trip to','travelling to', 'moving to',\n",
    "                   'relocating to', 'flying to', \"vist \", 'will be going', 'will be at ',\n",
    "                   'will be in ', 'tomorrow', 'next week', 'next days', 'next Monday',\n",
    "                   'next Tuesday', 'next Wednesday', 'next Thursday', 'next Friday', \n",
    "                   'next Saturday', 'next Sunday', 'tonight at', 'join us for', 'on mondays',\n",
    "                   'on tuesdays', 'on wednesdays', 'on Thursdays', 'on fridays', 'on saturdays',\n",
    "                   'on sundays', 'on weekends', 'on weekends', 'weeks from now', 'next stop ',\n",
    "                   'move to ', 'later on ', 'later this ' ]\n",
    "\"\"\"\"\n",
    "#future_searched = '|'.join(future_keywords) # for searching keywords within sentence structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filtering data to return only future mentions \n",
    "\n",
    "#df_future = df[df[\"clean_text\"].str.contains(future_searched, case = False, na = False)]\n",
    "#df_future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to Table of Contents](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
